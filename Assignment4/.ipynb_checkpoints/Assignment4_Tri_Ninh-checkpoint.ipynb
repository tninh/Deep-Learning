{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ex4_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df.iloc[:,400]\n",
    "x_train = df.iloc[:,0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.matrix(x_train)\n",
    "y_train = np.matrix(y_train).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = y_train\n",
    "depth = 10\n",
    "a = tf.one_hot(indices, depth, on_value = 1.0, off_value = 0.0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "y_train_encoded = sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_encoded = np.matrix(y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('ex4_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = df1.iloc[:,400]\n",
    "x_test = df1.iloc[:,0:400]\n",
    "x_test = np.matrix(x_test)\n",
    "y_test = np.matrix(y_test).T\n",
    "indices = y_test\n",
    "depth = 10\n",
    "b = tf.one_hot(indices, depth, on_value = 1.0, off_value = 0.0, axis=1)\n",
    "sess = tf.Session()\n",
    "y_test_encoded = sess.run(b)\n",
    "y_test_encoded = np.matrix(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "#     return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "    correct = [1 if a == b else 0 for (a, b) in zip(np.array(labels), predictions)]  \n",
    "    accuracy = (float(sum(map(int, correct))) / float(len(correct)))  \n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define Functions, neural network model and predictions__\n",
    "- Because of the structure of tensorflow, I defined all functions (built-in by TensorFlow) in one graph and use those functions to build a model in the same graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_nodes_1 = 150\n",
    "hidden_nodes_2 = 50\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_data = tf.placeholder(dtype=tf.float32, shape=(x_train.shape[0], x_train.shape[1]))\n",
    "    tf_train_labels = tf.placeholder(dtype=tf.float32, shape=(y_train_encoded.shape[0], y_train_encoded.shape[1]))\n",
    "    tf_test_data = tf.constant(x_test, dtype=tf.float32)\n",
    "    initializers = tf.contrib.layers.xavier_initializer(seed=1, dtype=tf.float32)\n",
    "    weights_1 = tf.Variable(initializers([x_train.shape[1], hidden_nodes_1]))\n",
    "    bias_1 = tf.Variable(tf.zeros([hidden_nodes_1], dtype=tf.float32))\n",
    "    weights_2 = tf.Variable(initializers([hidden_nodes_1,hidden_nodes_2]))\n",
    "    bias_2 = tf.Variable(tf.zeros([hidden_nodes_2]))\n",
    "    weights_3 = tf.Variable(initializers([hidden_nodes_2, 10]))\n",
    "    bias_3 = tf.Variable(tf.zeros([10]))\n",
    "    \n",
    "    logits_1 = tf.matmul(tf_train_data, weights_1) + bias_1\n",
    "    activation_1 = tf.nn.relu(logits_1)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    layer_1_dropout = tf.nn.dropout(activation_1, keep_prob)\n",
    "    \n",
    "    logits_2 = tf.matmul(layer_1_dropout, weights_2) + bias_2\n",
    "    activation_2 = tf.nn.relu(logits_2)\n",
    "    layer_2_dropout = tf.nn.dropout(activation_2, keep_prob)\n",
    "    \n",
    "    logits_3 = tf.matmul(layer_2_dropout, weights_3) + bias_3\n",
    "    activation_3 = tf.sigmoid(logits_3)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = activation_3, labels = tf_train_labels))\n",
    "    \n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    starting_learning_rate = 0.001\n",
    "    #learning_rate = tf.train.exponential_decay(starting_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "    optimizer = tf.train.AdamOptimizer(starting_learning_rate).minimize(cost, global_step = global_step)\n",
    "    \n",
    "    train_predictions = tf.argmax(tf.nn.softmax(activation_3), axis=1)\n",
    "    \n",
    "    logits_test_1 = tf.matmul(tf_test_data, weights_1) + bias_1\n",
    "    activation_test_1 = tf.nn.relu(logits_test_1)\n",
    "    \n",
    "    logits_test_2 = tf.matmul(activation_test_1, weights_2) + bias_2\n",
    "    activation_test_2 = tf.nn.relu(logits_test_2)\n",
    "    \n",
    "    \n",
    "    logits_test_3 = tf.matmul(activation_test_2, weights_3) + bias_3\n",
    "    activation_test_3 = tf.nn.sigmoid(logits_test_3)\n",
    "    test_prediction = tf.argmax(tf.nn.softmax(logits_test_3), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data has been splitted so I took the whole train set for training to improve the accuracy and test with the test set\n",
    "- Predictions is made right after the training process for each iterations to calculate cost and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Cost at step 0: 2.3411796093\n",
      "Accuracy training set: 9.3\n",
      "Cost at step 500: 1.68450772762\n",
      "Accuracy training set: 72.3\n",
      "Cost at step 1000: 1.62838160992\n",
      "Accuracy training set: 77.7\n",
      "Accuracy test set:91.5\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1500\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print \"Initialized\"\n",
    "    #k = tf.convert_to_tensor(keep_prob[0], dtype=np.float32)\n",
    "    #k = keep_prob[0]\n",
    "#     keep_prob = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#     keep_prob = np.matrix(keep_prob).T\n",
    "    #keep_probs = tf.constant(keep_prob, dtype = tf.float32)\n",
    "    for step in range(num_steps):\n",
    "        feed_dict = {tf_train_data: x_train, tf_train_labels:y_train_encoded, keep_prob:0.2}\n",
    "        _,c, predictions = session.run([optimizer, cost, train_predictions], feed_dict=feed_dict)\n",
    "        if (step % 500 ==0):\n",
    "            print(\"Cost at step {}: {}\".format(step,c))\n",
    "            a = accuracy(predictions, y_train)\n",
    "            print(\"Accuracy training set: {:,.1f}\".format(a))\n",
    "#             print \"Predictions:\"\n",
    "#             print type(predictions)\n",
    "    train_accuracies.append(a)\n",
    "    t = accuracy(test_prediction.eval(), y_test)\n",
    "    print(\"Accuracy test set:{:,.1f}\".format(t))\n",
    "    test_accuracies.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Cost at step 0: 2.3242957592\n",
      "Accuracy training set: 9.9\n",
      "Cost at step 500: 1.5914927721\n",
      "Accuracy training set: 87.3\n",
      "Cost at step 1000: 1.54493260384\n",
      "Accuracy training set: 90.9\n",
      "Accuracy test set:92.3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print \"Initialized\"\n",
    "    #k = tf.convert_to_tensor(keep_prob[0], dtype=np.float32)\n",
    "    #k = keep_prob[0]\n",
    "#     keep_prob = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#     keep_prob = np.matrix(keep_prob).T\n",
    "    #keep_probs = tf.constant(keep_prob, dtype = tf.float32)\n",
    "    for step in range(num_steps):\n",
    "        feed_dict = {tf_train_data: x_train, tf_train_labels:y_train_encoded, keep_prob:0.3}\n",
    "        _,c, predictions = session.run([optimizer, cost, train_predictions], feed_dict=feed_dict)\n",
    "        if (step % 500 ==0):\n",
    "            print(\"Cost at step {}: {}\".format(step,c))\n",
    "            a = accuracy(predictions, y_train)\n",
    "            print(\"Accuracy training set: {:,.1f}\".format(a))\n",
    "#             print \"Predictions:\"\n",
    "#             print type(predictions)\n",
    "    train_accuracies.append(a)\n",
    "    t = accuracy(test_prediction.eval(), y_test)\n",
    "    print(\"Accuracy test set:{:,.1f}\".format(t))\n",
    "    test_accuracies.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Cost at step 0: 2.31321048737\n",
      "Accuracy training set: 9.6\n",
      "Cost at step 500: 1.51798522472\n",
      "Accuracy training set: 95.4\n",
      "Cost at step 1000: 1.49210882187\n",
      "Accuracy training set: 97.6\n",
      "Accuracy test set:93.7\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print \"Initialized\"\n",
    "    #k = tf.convert_to_tensor(keep_prob[0], dtype=np.float32)\n",
    "    #k = keep_prob[0]\n",
    "#     keep_prob = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#     keep_prob = np.matrix(keep_prob).T\n",
    "    #keep_probs = tf.constant(keep_prob, dtype = tf.float32)\n",
    "    for step in range(num_steps):\n",
    "        feed_dict = {tf_train_data: x_train, tf_train_labels:y_train_encoded, keep_prob:0.5}\n",
    "        _,c, predictions = session.run([optimizer, cost, train_predictions], feed_dict=feed_dict)\n",
    "        if (step % 500 ==0):\n",
    "            print(\"Cost at step {}: {}\".format(step,c))\n",
    "            a = accuracy(predictions, y_train)\n",
    "            print(\"Accuracy training set: {:,.1f}\".format(a))\n",
    "#             print \"Predictions:\"\n",
    "#             print type(predictions)\n",
    "    train_accuracies.append(a)\n",
    "    t = accuracy(test_prediction.eval(), y_test)\n",
    "    print(\"Accuracy test set:{:,.1f}\".format(t))\n",
    "    test_accuracies.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Cost at step 0: 2.31097865105\n",
      "Accuracy training set: 10.5\n",
      "Cost at step 500: 1.49243724346\n",
      "Accuracy training set: 97.6\n",
      "Cost at step 1000: 1.4751598835\n",
      "Accuracy training set: 99.1\n",
      "Accuracy test set:94.3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print \"Initialized\"\n",
    "    #k = tf.convert_to_tensor(keep_prob[0], dtype=np.float32)\n",
    "    #k = keep_prob[0]\n",
    "#     keep_prob = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#     keep_prob = np.matrix(keep_prob).T\n",
    "    #keep_probs = tf.constant(keep_prob, dtype = tf.float32)\n",
    "    for step in range(num_steps):\n",
    "        feed_dict = {tf_train_data: x_train, tf_train_labels:y_train_encoded, keep_prob:0.7}\n",
    "        _,c, predictions = session.run([optimizer, cost, train_predictions], feed_dict=feed_dict)\n",
    "        if (step % 500 ==0):\n",
    "            print(\"Cost at step {}: {}\".format(step,c))\n",
    "            a = accuracy(predictions, y_train)\n",
    "            print(\"Accuracy training set: {:,.1f}\".format(a))\n",
    "#             print \"Predictions:\"\n",
    "#             print type(predictions)\n",
    "    train_accuracies.append(a)\n",
    "    t = accuracy(test_prediction.eval(), y_test)\n",
    "    print(\"Accuracy test set:{:,.1f}\".format(t))\n",
    "    test_accuracies.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Cost at step 0: 2.30977797508\n",
      "Accuracy training set: 10.0\n",
      "Cost at step 500: 1.4860714674\n",
      "Accuracy training set: 98.0\n",
      "Cost at step 1000: 1.47244811058\n",
      "Accuracy training set: 99.1\n",
      "Accuracy test set:94.3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print \"Initialized\"\n",
    "    #k = tf.convert_to_tensor(keep_prob[0], dtype=np.float32)\n",
    "    #k = keep_prob[0]\n",
    "#     keep_prob = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#     keep_prob = np.matrix(keep_prob).T\n",
    "    #keep_probs = tf.constant(keep_prob, dtype = tf.float32)\n",
    "    for step in range(num_steps):\n",
    "        feed_dict = {tf_train_data: x_train, tf_train_labels:y_train_encoded, keep_prob:0.8}\n",
    "        _,c, predictions = session.run([optimizer, cost, train_predictions], feed_dict=feed_dict)\n",
    "        if (step % 500 ==0):\n",
    "            print(\"Cost at step {}: {}\".format(step,c))\n",
    "            a = accuracy(predictions, y_train)\n",
    "            print(\"Accuracy training set: {:,.1f}\".format(a))\n",
    "#             print \"Predictions:\"\n",
    "#             print type(predictions)\n",
    "    train_accuracies.append(a)\n",
    "    t = accuracy(test_prediction.eval(), y_test)\n",
    "    print(\"Accuracy test set:{:,.1f}\".format(t))\n",
    "    test_accuracies.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Cost at step 0: 2.31002449989\n",
      "Accuracy training set: 11.1\n",
      "Cost at step 500: 1.47906553745\n",
      "Accuracy training set: 98.7\n",
      "Cost at step 1000: 1.47021794319\n",
      "Accuracy training set: 99.3\n",
      "Accuracy test set:94.4\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print \"Initialized\"\n",
    "    #k = tf.convert_to_tensor(keep_prob[0], dtype=np.float32)\n",
    "    #k = keep_prob[0]\n",
    "#     keep_prob = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#     keep_prob = np.matrix(keep_prob).T\n",
    "    #keep_probs = tf.constant(keep_prob, dtype = tf.float32)\n",
    "    for step in range(num_steps):\n",
    "        feed_dict = {tf_train_data: x_train, tf_train_labels:y_train_encoded, keep_prob:0.9}\n",
    "        _,c, predictions = session.run([optimizer, cost, train_predictions], feed_dict=feed_dict)\n",
    "        if (step % 500 ==0):\n",
    "            print(\"Cost at step {}: {}\".format(step,c))\n",
    "            a = accuracy(predictions, y_train)\n",
    "            print(\"Accuracy training set: {:,.1f}\".format(a))\n",
    "#             print \"Predictions:\"\n",
    "#             print type(predictions)\n",
    "    train_accuracies.append(a)\n",
    "    t = accuracy(test_prediction.eval(), y_test)\n",
    "    print(\"Accuracy test set:{:,.1f}\".format(t))\n",
    "    test_accuracies.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127e9ced0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_prob = [0.2,0.3, 0.5, 0.7, 0.8, 0.9]\n",
    "plt.plot(keep_prob,test_accuracies, color='green')\n",
    "plt.plot(keep_prob,train_accuracies, color='red')\n",
    "plt.legend(['test_accuracies', 'train_accuracies'], loc='upper left')\n",
    "plt.xlabel('keep_prob')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topKFrequent(nums, k):\n",
    "        \"\"\"\n",
    "        :type nums: List[int]\n",
    "        :type k: int\n",
    "        :rtype: List[int]\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        counts = []\n",
    "        count = 1\n",
    "        nums_sorted = sorted(nums)\n",
    "        for i in range(0, len(nums_sorted)):\n",
    "            for j in range(1, len(nums)):\n",
    "                if (nums_sorted[i] == nums_sorted[j] and nums_sorted[i] != nums_sorted[i - 1]):\n",
    "                    count = count + 1\n",
    "            counts.append(count)\n",
    "            count = 1\n",
    "                    \n",
    "        #counts.sort()\n",
    "        print counts\n",
    "        print nums[5]\n",
    "        print [i for i, j in enumerate(counts) if j == max(counts)]\n",
    "        for j in range(0, k):\n",
    "            if counts\n",
    "            results.append(nums[len(counts) - j -1])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 1, 3, 1, 2]\n",
      "3\n",
      "[0, 3]\n"
     ]
    }
   ],
   "source": [
    "results = topKFrequent([1,1,1,2,2,3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
